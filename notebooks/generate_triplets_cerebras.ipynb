{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation de Triplets Synthetiques - Pocket Arbiter\n",
    "\n",
    "> **Objectif**: Generer des questions synthetiques pour fine-tuner un modele d'embeddings\n",
    ">\n",
    "> **API**: Cerebras (gratuit, 24M tokens/jour, ~2600 tok/s)\n",
    ">\n",
    "> **Corpus**: FFE (francais) + FIDE (anglais)\n",
    "\n",
    "## Setup Kaggle\n",
    "\n",
    "1. **Add Secret**: Settings > Secrets > Add `CEREBRAS_API_KEY`\n",
    "2. **Upload Data**: Uploader `chunks_for_embedding_fr.json` et `chunks_for_embedding_intl.json`\n",
    "3. **Run All**: Executer toutes les cellules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des dependances\n",
    "!pip install -q cerebras-cloud-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "\n",
    "from cerebras.cloud.sdk import Cerebras\n",
    "\n",
    "# Kaggle Secrets\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    secrets = UserSecretsClient()\n",
    "    CEREBRAS_API_KEY = secrets.get_secret(\"CEREBRAS_API_KEY\")\n",
    "    print(\"API key loaded from Kaggle Secrets\")\n",
    "except:\n",
    "    CEREBRAS_API_KEY = os.environ.get(\"CEREBRAS_API_KEY\")\n",
    "    print(\"API key loaded from environment\")\n",
    "\n",
    "# Configuration\n",
    "MODEL = \"llama-3.3-70b\"  # Modele rapide et performant\n",
    "QUESTIONS_PER_CHUNK = 3\n",
    "MAX_RETRIES = 3\n",
    "RETRY_DELAY = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categories de Questions Metier\n",
    "\n",
    "Trois categories adaptees aux besoins reels des arbitres d'echecs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories de questions par corpus\n",
    "QUESTION_CATEGORIES = {\n",
    "    \"ffe\": {\n",
    "        \"arbitre_terrain\": {\n",
    "            \"description\": \"Questions d'un arbitre experimente sur le terrain (cas particuliers)\",\n",
    "            \"examples\": [\n",
    "                \"Quel sera l'Elo d'un joueur apres ce tournoi avec ces resultats?\",\n",
    "                \"Quels sont les affichages obligatoires en salle de jeu?\",\n",
    "                \"Un portable sonne pendant la partie, quelle sanction?\",\n",
    "                \"Le joueur arrive 10 minutes apres le debut, est-il forfait?\",\n",
    "                \"Comment gerer une reclamation sur un mat illegal?\",\n",
    "                \"Quelle est la procedure si un joueur refuse de signer la feuille?\",\n",
    "            ],\n",
    "        },\n",
    "        \"arbitre_organisateur\": {\n",
    "            \"description\": \"Questions pour l'organisation d'un tournoi ou formation arbitrale\",\n",
    "            \"examples\": [\n",
    "                \"Quelles sont les conditions pour devenir arbitre AF2?\",\n",
    "                \"Quel est le delai d'homologation d'un tournoi FFE?\",\n",
    "                \"Quel materiel est obligatoire pour un tournoi homologue?\",\n",
    "                \"Comment calculer les droits d'engagement?\",\n",
    "                \"Quelle est la procedure pour homologuer un open?\",\n",
    "                \"Combien d'arbitres faut-il pour un tournoi de 100 joueurs?\",\n",
    "            ],\n",
    "        },\n",
    "        \"question_joueur\": {\n",
    "            \"description\": \"Questions posees par des joueurs (langage oral/verbal)\",\n",
    "            \"examples\": [\n",
    "                \"J'ai le droit de proposer nulle quand exactement?\",\n",
    "                \"Il a touche une piece, il doit la jouer non?\",\n",
    "                \"C'est quoi le departage au juste?\",\n",
    "                \"Je peux aller aux toilettes pendant ma partie?\",\n",
    "                \"Mon adversaire ecrit ses coups avant de jouer, c'est legal?\",\n",
    "                \"J'ai oublie d'appuyer sur la pendule, qu'est-ce qui se passe?\",\n",
    "            ],\n",
    "        },\n",
    "    },\n",
    "    \"fide\": {\n",
    "        \"arbiter_field\": {\n",
    "            \"description\": \"Questions from an experienced arbiter during a tournament\",\n",
    "            \"examples\": [\n",
    "                \"What is the penalty for a mobile phone ringing?\",\n",
    "                \"How to handle a claim of threefold repetition?\",\n",
    "                \"When can a player claim a draw under the 50-move rule?\",\n",
    "                \"What happens if a player makes an illegal move in time trouble?\",\n",
    "                \"How to proceed when both flags have fallen?\",\n",
    "            ],\n",
    "        },\n",
    "        \"arbiter_organizer\": {\n",
    "            \"description\": \"Questions for tournament organization or arbiter certification\",\n",
    "            \"examples\": [\n",
    "                \"What are the requirements to become a FIDE Arbiter?\",\n",
    "                \"What equipment is mandatory for a FIDE-rated tournament?\",\n",
    "                \"How to submit results for FIDE rating?\",\n",
    "                \"What is the time control for classical FIDE games?\",\n",
    "            ],\n",
    "        },\n",
    "        \"player_question\": {\n",
    "            \"description\": \"Questions asked by players (natural spoken language)\",\n",
    "            \"examples\": [\n",
    "                \"Can I offer a draw before making my move?\",\n",
    "                \"My opponent touched a piece, does he have to move it?\",\n",
    "                \"What's the tiebreak system in this tournament?\",\n",
    "                \"Am I allowed to leave the playing hall?\",\n",
    "            ],\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts de Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_ffe(categories: dict, num_questions: int) -> str:\n",
    "    \"\"\"Build system prompt for FFE corpus (French).\"\"\"\n",
    "    cat_terrain = categories[\"arbitre_terrain\"]\n",
    "    cat_orga = categories[\"arbitre_organisateur\"]\n",
    "    cat_joueur = categories[\"question_joueur\"]\n",
    "\n",
    "    examples_terrain = \"\\n\".join(f\"  - {ex}\" for ex in cat_terrain[\"examples\"][:3])\n",
    "    examples_orga = \"\\n\".join(f\"  - {ex}\" for ex in cat_orga[\"examples\"][:3])\n",
    "    examples_joueur = \"\\n\".join(f\"  - {ex}\" for ex in cat_joueur[\"examples\"][:3])\n",
    "\n",
    "    return f\"\"\"Tu es un arbitre d'echecs FFE experimente (AF3 minimum).\n",
    "Tu generes des questions REALISTES que l'on te pose sur le terrain ou en formation.\n",
    "\n",
    "TROIS CATEGORIES DE QUESTIONS (varier obligatoirement):\n",
    "\n",
    "1. ARBITRE TERRAIN - Cas particuliers concrets en competition:\n",
    "{examples_terrain}\n",
    "\n",
    "2. ARBITRE ORGANISATEUR - Organisation tournoi ou formation arbitrale:\n",
    "{examples_orga}\n",
    "\n",
    "3. JOUEUR - Questions orales d'un joueur (langage familier, verbal):\n",
    "{examples_joueur}\n",
    "\n",
    "REGLES STRICTES:\n",
    "- Langue: FRANCAIS uniquement\n",
    "- La reponse DOIT etre trouvable dans le texte fourni\n",
    "- Style: questions naturelles, pas academiques\n",
    "- Jargon FFE: Elo, cadence, forfait, appariement, homologation, departage\n",
    "- Genere {num_questions} questions: au moins 1 de chaque categorie si possible\n",
    "\n",
    "FORMAT JSON UNIQUEMENT (pas de texte autour):\n",
    "{{\"questions\": [{{\"question\": \"...\", \"category\": \"arbitre_terrain|arbitre_organisateur|question_joueur\", \"difficulty\": \"easy|medium|hard\"}}]}}\"\"\"\n",
    "\n",
    "\n",
    "def build_prompt_fide(categories: dict, num_questions: int) -> str:\n",
    "    \"\"\"Build system prompt for FIDE corpus (English).\"\"\"\n",
    "    cat_field = categories[\"arbiter_field\"]\n",
    "    cat_orga = categories[\"arbiter_organizer\"]\n",
    "    cat_player = categories[\"player_question\"]\n",
    "\n",
    "    examples_field = \"\\n\".join(f\"  - {ex}\" for ex in cat_field[\"examples\"][:3])\n",
    "    examples_orga = \"\\n\".join(f\"  - {ex}\" for ex in cat_orga[\"examples\"][:3])\n",
    "    examples_player = \"\\n\".join(f\"  - {ex}\" for ex in cat_player[\"examples\"][:3])\n",
    "\n",
    "    return f\"\"\"You are an experienced FIDE arbiter (IA or FA level).\n",
    "Generate REALISTIC questions that arbiters or players ask during tournaments.\n",
    "\n",
    "THREE CATEGORIES OF QUESTIONS (must vary):\n",
    "\n",
    "1. ARBITER ON FIELD - Specific cases during competition:\n",
    "{examples_field}\n",
    "\n",
    "2. ARBITER/ORGANIZER - Tournament organization or certification:\n",
    "{examples_orga}\n",
    "\n",
    "3. PLAYER - Oral questions from players (casual spoken language):\n",
    "{examples_player}\n",
    "\n",
    "STRICT RULES:\n",
    "- Language: ENGLISH only\n",
    "- The answer MUST be found in the provided text\n",
    "- Style: natural questions, not academic\n",
    "- FIDE terminology: rating, time control, forfeit, pairing, tiebreak\n",
    "- Generate {num_questions} questions: at least 1 from each category if possible\n",
    "\n",
    "JSON FORMAT ONLY (no surrounding text):\n",
    "{{\"questions\": [{{\"question\": \"...\", \"category\": \"arbiter_field|arbiter_organizer|player_question\", \"difficulty\": \"easy|medium|hard\"}}]}}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction de Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(\n",
    "    client: Cerebras,\n",
    "    chunk_text: str,\n",
    "    chunk_id: str,\n",
    "    corpus: str = \"ffe\",\n",
    "    num_questions: int = 3,\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Generate synthetic questions for a chunk using Cerebras API.\n",
    "\n",
    "    Args:\n",
    "        client: Cerebras client\n",
    "        chunk_text: Text content of the chunk\n",
    "        chunk_id: Unique identifier for the chunk\n",
    "        corpus: \"ffe\" (French) or \"fide\" (English)\n",
    "        num_questions: Number of questions to generate\n",
    "\n",
    "    Returns:\n",
    "        List of question dicts with keys: question, category, difficulty, chunk_id\n",
    "    \"\"\"\n",
    "    categories = QUESTION_CATEGORIES.get(corpus, QUESTION_CATEGORIES[\"ffe\"])\n",
    "\n",
    "    if corpus == \"fide\":\n",
    "        system_prompt = build_prompt_fide(categories, num_questions)\n",
    "        user_prompt = f\"\"\"FIDE regulatory text:\n",
    "\\\"\\\"\\\"\n",
    "{chunk_text[:2500]}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "Generate exactly {num_questions} varied questions based on this text.\"\"\"\n",
    "    else:\n",
    "        system_prompt = build_prompt_ffe(categories, num_questions)\n",
    "        user_prompt = f\"\"\"Texte reglementaire FFE:\n",
    "\\\"\\\"\\\"\n",
    "{chunk_text[:2500]}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "Genere exactement {num_questions} questions variees basees sur ce texte.\"\"\"\n",
    "\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt},\n",
    "                ],\n",
    "                max_completion_tokens=800,\n",
    "                temperature=0.7,\n",
    "                top_p=1,\n",
    "            )\n",
    "\n",
    "            content = response.choices[0].message.content\n",
    "            if content is None:\n",
    "                continue\n",
    "            \n",
    "            content = content.strip()\n",
    "\n",
    "            # Extract JSON\n",
    "            if \"```json\" in content:\n",
    "                content = content.split(\"```json\")[1].split(\"```\")[0]\n",
    "            elif \"```\" in content:\n",
    "                parts = content.split(\"```\")\n",
    "                if len(parts) >= 2:\n",
    "                    content = parts[1]\n",
    "\n",
    "            # Find JSON object\n",
    "            start = content.find(\"{\")\n",
    "            if start >= 0:\n",
    "                depth = 0\n",
    "                for i, c in enumerate(content[start:]):\n",
    "                    if c == \"{\":\n",
    "                        depth += 1\n",
    "                    elif c == \"}\":\n",
    "                        depth -= 1\n",
    "                        if depth == 0:\n",
    "                            content = content[start:start + i + 1]\n",
    "                            break\n",
    "\n",
    "            data = json.loads(content)\n",
    "            questions = data.get(\"questions\", [])\n",
    "\n",
    "            # Add metadata\n",
    "            for q in questions:\n",
    "                q[\"chunk_id\"] = chunk_id\n",
    "                q[\"corpus\"] = corpus\n",
    "\n",
    "            return questions\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            if attempt < MAX_RETRIES - 1:\n",
    "                time.sleep(RETRY_DELAY)\n",
    "            else:\n",
    "                print(f\"  JSON error {chunk_id}: {e}\")\n",
    "                return []\n",
    "        except Exception as e:\n",
    "            if attempt < MAX_RETRIES - 1:\n",
    "                time.sleep(RETRY_DELAY)\n",
    "            else:\n",
    "                print(f\"  Error {chunk_id}: {type(e).__name__}: {e}\")\n",
    "                return []\n",
    "\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline de Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_generation(\n",
    "    chunks: list[dict],\n",
    "    corpus: str = \"ffe\",\n",
    "    max_chunks: Optional[int] = None,\n",
    "    questions_per_chunk: int = 3,\n",
    "    checkpoint_every: int = 100,\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Run question generation pipeline.\n",
    "\n",
    "    Args:\n",
    "        chunks: List of chunks with 'id' and 'text' keys\n",
    "        corpus: \"ffe\" (French) or \"fide\" (English)\n",
    "        max_chunks: Limit number of chunks (None = all)\n",
    "        questions_per_chunk: Questions to generate per chunk\n",
    "        checkpoint_every: Save checkpoint every N chunks\n",
    "\n",
    "    Returns:\n",
    "        List of all generated questions\n",
    "    \"\"\"\n",
    "    # Setup client\n",
    "    client = Cerebras(api_key=CEREBRAS_API_KEY)\n",
    "\n",
    "    if max_chunks:\n",
    "        chunks = chunks[:max_chunks]\n",
    "\n",
    "    lang = \"francais\" if corpus == \"ffe\" else \"english\"\n",
    "    print(f\"=\" * 60)\n",
    "    print(f\"CEREBRAS TRIPLET GENERATION\")\n",
    "    print(f\"=\" * 60)\n",
    "    print(f\"Model: {MODEL}\")\n",
    "    print(f\"Corpus: {corpus.upper()} ({lang})\")\n",
    "    print(f\"Chunks: {len(chunks)}\")\n",
    "    print(f\"Questions/chunk: {questions_per_chunk}\")\n",
    "    print(f\"Estimated total: {len(chunks) * questions_per_chunk}\")\n",
    "    print(f\"=\" * 60)\n",
    "    print()\n",
    "\n",
    "    all_questions: list[dict] = []\n",
    "    errors = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_id = chunk.get(\"id\", f\"chunk-{i}\")\n",
    "        chunk_text = chunk.get(\"text\", \"\")\n",
    "\n",
    "        # Progress\n",
    "        if i % 10 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            rate = len(all_questions) / elapsed * 60 if elapsed > 0 else 0\n",
    "            print(f\"[{i:4d}/{len(chunks)}] {len(all_questions):4d} questions ({rate:.1f}/min)\")\n",
    "\n",
    "        questions = generate_questions(\n",
    "            client=client,\n",
    "            chunk_text=chunk_text,\n",
    "            chunk_id=chunk_id,\n",
    "            corpus=corpus,\n",
    "            num_questions=questions_per_chunk,\n",
    "        )\n",
    "\n",
    "        if questions:\n",
    "            all_questions.extend(questions)\n",
    "        else:\n",
    "            errors += 1\n",
    "\n",
    "        # Checkpoint\n",
    "        if (i + 1) % checkpoint_every == 0:\n",
    "            checkpoint_path = f\"checkpoint_{corpus}_{i+1}.json\"\n",
    "            with open(checkpoint_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(all_questions, f, ensure_ascii=False, indent=2)\n",
    "            print(f\"  >> Checkpoint saved: {checkpoint_path}\")\n",
    "\n",
    "    # Final stats\n",
    "    elapsed = time.time() - start_time\n",
    "    print()\n",
    "    print(f\"=\" * 60)\n",
    "    print(f\"DONE ({corpus.upper()})\")\n",
    "    print(f\"=\" * 60)\n",
    "    print(f\"Total questions: {len(all_questions)}\")\n",
    "    print(f\"Errors: {errors}\")\n",
    "    print(f\"Time: {elapsed/60:.1f} min\")\n",
    "    print(f\"Rate: {len(all_questions)/elapsed*60:.1f} questions/min\")\n",
    "\n",
    "    return all_questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des Chunks\n",
    "\n",
    "**Option 1**: Upload les fichiers JSON dans Kaggle\n",
    "\n",
    "**Option 2**: Charger depuis GitHub (cell ci-dessous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Charger depuis fichiers uploades\n",
    "def load_chunks_from_file(path: str) -> list[dict]:\n",
    "    \"\"\"Load chunks from uploaded JSON file.\"\"\"\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    # Handle both formats: list or {\"chunks\": [...]}\n",
    "    return data.get(\"chunks\", data) if isinstance(data, dict) else data\n",
    "\n",
    "# Option 2: Charger depuis GitHub\n",
    "def load_chunks_from_github(corpus: str = \"fr\") -> list[dict]:\n",
    "    \"\"\"Load chunks directly from GitHub repo.\"\"\"\n",
    "    import urllib.request\n",
    "    \n",
    "    base_url = \"https://raw.githubusercontent.com/YOUR_USERNAME/pocket_arbiter/main/corpus/processed\"\n",
    "    filename = f\"chunks_for_embedding_{corpus}.json\"\n",
    "    url = f\"{base_url}/{filename}\"\n",
    "    \n",
    "    print(f\"Loading from: {url}\")\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        data = json.loads(response.read().decode(\"utf-8\"))\n",
    "    \n",
    "    chunks = data.get(\"chunks\", data) if isinstance(data, dict) else data\n",
    "    print(f\"Loaded {len(chunks)} chunks\")\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CHARGER LES CHUNKS (decommenter l'option choisie)\n",
    "# ============================================================\n",
    "\n",
    "# Option 1: Fichiers uploades sur Kaggle\n",
    "chunks_fr = load_chunks_from_file(\"/kaggle/input/pocket-arbiter-chunks/chunks_for_embedding_fr.json\")\n",
    "# chunks_intl = load_chunks_from_file(\"/kaggle/input/pocket-arbiter-chunks/chunks_for_embedding_intl.json\")\n",
    "\n",
    "# Option 2: Depuis GitHub (remplacer YOUR_USERNAME)\n",
    "# chunks_fr = load_chunks_from_github(\"fr\")\n",
    "# chunks_intl = load_chunks_from_github(\"intl\")\n",
    "\n",
    "print(f\"Chunks FR: {len(chunks_fr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test sur 5 Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test rapide sur 5 chunks\n",
    "test_questions = run_generation(\n",
    "    chunks=chunks_fr,\n",
    "    corpus=\"ffe\",\n",
    "    max_chunks=5,\n",
    "    questions_per_chunk=3,\n",
    ")\n",
    "\n",
    "# Afficher les resultats\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXEMPLES DE QUESTIONS GENEREES\")\n",
    "print(\"=\" * 60)\n",
    "for q in test_questions[:9]:\n",
    "    print(f\"\\n[{q.get('category', 'N/A')}] {q.get('difficulty', 'N/A')}\")\n",
    "    print(f\"  Q: {q['question']}\")\n",
    "    print(f\"  Chunk: {q['chunk_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation Complete FFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# GENERATION COMPLETE FFE (decommenter pour lancer)\n",
    "# Temps estime: ~30-60 min pour 1827 chunks\n",
    "# ============================================================\n",
    "\n",
    "# questions_ffe = run_generation(\n",
    "#     chunks=chunks_fr,\n",
    "#     corpus=\"ffe\",\n",
    "#     max_chunks=None,  # Tous les chunks\n",
    "#     questions_per_chunk=3,\n",
    "#     checkpoint_every=100,\n",
    "# )\n",
    "\n",
    "# # Sauvegarder\n",
    "# output_path = \"synthetic_questions_ffe.json\"\n",
    "# with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(questions_ffe, f, ensure_ascii=False, indent=2)\n",
    "# print(f\"\\nSaved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation Complete FIDE (optionnel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# GENERATION COMPLETE FIDE (decommenter pour lancer)\n",
    "# ============================================================\n",
    "\n",
    "# chunks_intl = load_chunks_from_file(\"/kaggle/input/pocket-arbiter-chunks/chunks_for_embedding_intl.json\")\n",
    "\n",
    "# questions_fide = run_generation(\n",
    "#     chunks=chunks_intl,\n",
    "#     corpus=\"fide\",\n",
    "#     max_chunks=None,\n",
    "#     questions_per_chunk=3,\n",
    "#     checkpoint_every=100,\n",
    "# )\n",
    "\n",
    "# # Sauvegarder\n",
    "# output_path = \"synthetic_questions_fide.json\"\n",
    "# with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(questions_fide, f, ensure_ascii=False, indent=2)\n",
    "# print(f\"\\nSaved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistiques et Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stats(questions: list[dict]) -> dict:\n",
    "    \"\"\"Compute statistics on generated questions.\"\"\"\n",
    "    stats = {\n",
    "        \"total\": len(questions),\n",
    "        \"by_category\": {},\n",
    "        \"by_difficulty\": {},\n",
    "        \"unique_chunks\": len(set(q.get(\"chunk_id\", \"\") for q in questions)),\n",
    "    }\n",
    "    \n",
    "    for q in questions:\n",
    "        cat = q.get(\"category\", \"unknown\")\n",
    "        diff = q.get(\"difficulty\", \"unknown\")\n",
    "        stats[\"by_category\"][cat] = stats[\"by_category\"].get(cat, 0) + 1\n",
    "        stats[\"by_difficulty\"][diff] = stats[\"by_difficulty\"].get(diff, 0) + 1\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Exemple d'utilisation\n",
    "if 'test_questions' in dir() and test_questions:\n",
    "    stats = compute_stats(test_questions)\n",
    "    print(\"\\nStatistiques:\")\n",
    "    print(f\"  Total: {stats['total']}\")\n",
    "    print(f\"  Chunks uniques: {stats['unique_chunks']}\")\n",
    "    print(f\"  Par categorie: {stats['by_category']}\")\n",
    "    print(f\"  Par difficulte: {stats['by_difficulty']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download des Resultats\n",
    "\n",
    "Apres generation, telecharger les fichiers JSON depuis l'onglet **Output** de Kaggle,\n",
    "puis les committer dans le repo GitHub sous `data/synthetic_triplets/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des fichiers generes\n",
    "import os\n",
    "print(\"Fichiers generes:\")\n",
    "for f in os.listdir(\".\"):\n",
    "    if f.endswith(\".json\"):\n",
    "        size = os.path.getsize(f) / 1024\n",
    "        print(f\"  {f} ({size:.1f} KB)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
