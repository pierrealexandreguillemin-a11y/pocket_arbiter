{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Fine-tuning EmbeddingGemma pour Pocket Arbiter\n\n**ISO Reference**: ISO/IEC 42001 A.6.2.2, ISO/IEC 25010 S4.2\n\nCe notebook fine-tune EmbeddingGemma sur le domaine echecs/arbitrage FR.\n\n**Instructions**: Clique sur **Exécution** → **Tout exécuter** (c'est tout!)",
   "metadata": {
    "id": "header"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Installation des dependances\n",
    "!pip install -q sentence-transformers datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Verification GPU\n",
    "import torch\n",
    "print(f\"GPU disponible: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ],
   "metadata": {
    "id": "check_gpu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Telechargement automatique des donnees depuis GitHub\n!wget -q https://raw.githubusercontent.com/pierrealexandreguillemin-a11y/pocket_arbiter/main/data/training/triplets_training.jsonl\nprint(\"Donnees telechargees!\")",
   "metadata": {
    "id": "upload"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Chargement des triplets\n",
    "import json\n",
    "\n",
    "triplets = []\n",
    "with open(\"triplets_training.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            triplets.append(json.loads(line))\n",
    "\n",
    "print(f\"Triplets charges: {len(triplets)}\")\n",
    "print(f\"Exemple: {triplets[0]['anchor'][:50]}...\")"
   ],
   "metadata": {
    "id": "load_data"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Configuration\n# Note: multilingual-e5-base ne necessite pas d'authentification HuggingFace\nMODEL_ID = \"intfloat/multilingual-e5-base\"\nOUTPUT_DIR = \"embedding-chess-fr\"\nEPOCHS = 3\nBATCH_SIZE = 16\nLEARNING_RATE = 2e-5\nWARMUP_RATIO = 0.1",
   "metadata": {
    "id": "config"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Chargement du modele\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(f\"Chargement de {MODEL_ID}...\")\n",
    "model = SentenceTransformer(MODEL_ID)\n",
    "print(f\"Dimension: {model.get_sentence_embedding_dimension()}\")"
   ],
   "metadata": {
    "id": "load_model"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Preparation du dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_list(triplets)\n",
    "print(f\"Dataset: {len(dataset)} examples\")\n",
    "print(dataset)"
   ],
   "metadata": {
    "id": "prepare_dataset"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Configuration du training\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    ")\n",
    "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
    "\n",
    "# Loss function\n",
    "loss = MultipleNegativesRankingLoss(model)\n",
    "\n",
    "# Arguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    "    fp16=True,  # Mixed precision pour GPU\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "print(\"Training args configured\")"
   ],
   "metadata": {
    "id": "config_training"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Entrainement\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset,\n",
    "    loss=loss,\n",
    ")\n",
    "\n",
    "print(\"Debut de l'entrainement...\")\n",
    "trainer.train()\n",
    "print(\"Entrainement termine!\")"
   ],
   "metadata": {
    "id": "train"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Sauvegarde du modele\n",
    "model.save(OUTPUT_DIR)\n",
    "print(f\"Modele sauvegarde dans {OUTPUT_DIR}/\")"
   ],
   "metadata": {
    "id": "save"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Test du modele\n",
    "test_queries = [\n",
    "    \"Quelle est la regle du toucher-jouer ?\",\n",
    "    \"Comment fonctionne le roque ?\",\n",
    "    \"Que faire en cas de partie nulle ?\",\n",
    "]\n",
    "\n",
    "print(\"Test du modele fine-tune:\")\n",
    "for q in test_queries:\n",
    "    emb = model.encode(q)\n",
    "    print(f\"  {q[:40]}... -> {emb.shape}\")"
   ],
   "metadata": {
    "id": "test"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Telechargement du modele\nimport shutil\nfrom google.colab import files\n\n# Creer une archive\nshutil.make_archive(OUTPUT_DIR, 'zip', OUTPUT_DIR)\nprint(f\"Archive creee: {OUTPUT_DIR}.zip\")\n\n# Telecharger\nfiles.download(f\"{OUTPUT_DIR}.zip\")\nprint(\"Telechargement lance!\")",
   "metadata": {
    "id": "download"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prochaines etapes\n",
    "\n",
    "1. Extraire `embeddinggemma-chess-fr.zip` dans `models/`\n",
    "2. Executer `python -m scripts.training.evaluate_finetuned`\n",
    "3. Si recall >= 80%, regenerer les embeddings du corpus"
   ],
   "metadata": {
    "id": "next_steps"
   }
  }
 ]
}