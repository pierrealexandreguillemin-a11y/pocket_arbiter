"""
Multi-Vector Table Retriever - Pocket Arbiter

Implements multi-vector retrieval for tables:
- Embed table summaries (child) for semantic search
- Store raw tables (parent) in docstore for LLM synthesis
- Link via doc_id for parent-child retrieval

IMPORTANT: Summaries MUST be generated by Claude Code.
This module does NOT generate summaries - it structures data only.

ISO Reference:
    - ISO/IEC 42001 - AI traceability (Claude Code summaries)
    - ISO/IEC 25010 S4.2 - Performance efficiency
    - ISO/IEC 12207 S7.3.3 - Implementation

Usage:
    # Step 1: Claude Code generates summaries
    python -m scripts.pipeline.table_multivector \
        --input corpus/processed/docling_fr \
        --summaries corpus/processed/table_summaries_claude.json \
        --output corpus/processed/tables_multivector_fr.json

Changelog:
    - 2026-01-19: Refactor - Claude Code enforcement for summaries
"""

import argparse
import json
import logging
import sys
from pathlib import Path
from typing import Any

from pydantic import BaseModel, Field

logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
logger = logging.getLogger(__name__)


# --- Pydantic Models (ISO 25010 data quality) ---


class ChildDocument(BaseModel):
    """Child document for vectorstore (summary)."""

    id: str
    doc_id: str  # Link to parent
    type: str = "table_summary"
    text: str = Field(..., min_length=1)
    source: str | None = None
    page: int | None = None
    table_type: str = "other"


class ParentDocument(BaseModel):
    """Parent document for docstore (raw table)."""

    id: str
    type: str = "table"
    table_type: str = "other"
    source: str | None = None
    page: int | None = None
    headers: list[str] = Field(default_factory=list)
    rows: list[list[str]] = Field(default_factory=list)
    markdown: str = ""
    text: str = ""


# --- Helper Functions ---


def table_to_markdown(table: dict[str, Any]) -> str:
    """Convert table to Markdown format for LLM synthesis."""
    headers = table.get("headers", [])
    rows = table.get("rows", [])

    if not headers:
        return ""

    lines = []
    lines.append("| " + " | ".join(str(h) for h in headers) + " |")
    lines.append("| " + " | ".join("---" for _ in headers) + " |")

    for row in rows:
        padded = list(row) + [""] * (len(headers) - len(row))
        lines.append(
            "| " + " | ".join(str(cell) for cell in padded[: len(headers)]) + " |"
        )

    return "\n".join(lines)


def table_to_text(headers: list[str], rows: list[list[str]]) -> str:
    """Convert table to text for embedding/search."""
    lines = []
    if headers:
        lines.append(" | ".join(str(h) for h in headers))
        lines.append("-" * 40)
    for row in rows:
        lines.append(" | ".join(str(cell) for cell in row))
    return "\n".join(lines)


def load_tables_from_docling_dir(input_dir: Path) -> list[dict[str, Any]]:
    """Load tables from Docling extraction directory."""
    all_tables: list[dict[str, Any]] = []

    json_files = sorted(input_dir.glob("*.json"))
    logger.info(f"Found {len(json_files)} files in {input_dir}")

    for f in json_files:
        if f.name == "extraction_report.json":
            continue

        with open(f, encoding="utf-8") as fp:
            data = json.load(fp)

        tables = data.get("tables", [])
        for t in tables:
            if not t.get("table_type"):
                t["table_type"] = "other"
            all_tables.append(t)

    logger.info(f"Loaded {len(all_tables)} tables from {input_dir}")
    return all_tables


# --- Main Processing ---


def process_tables_multivector(
    input_path: Path,
    summaries_file: Path,
    output_file: Path,
    corpus: str = "fr",
) -> dict[str, Any]:
    """
    Process tables into multi-vector format.

    REQUIRES Claude Code summaries. Will FAIL without them.

    Args:
        input_path: Docling extraction directory.
        summaries_file: JSON file with Claude Code summaries.
        output_file: Output multi-vector JSON.
        corpus: Corpus name.

    Returns:
        Processing report.

    Raises:
        FileNotFoundError: If summaries file missing.
        ValueError: If summaries don't match tables.
    """
    # Load tables
    if input_path.is_dir():
        tables = load_tables_from_docling_dir(input_path)
    else:
        with open(input_path, encoding="utf-8") as f:
            data = json.load(f)
        tables = data.get("tables", [])

    # ENFORCE: Claude Code summaries required
    if not summaries_file.exists():
        logger.error("=" * 60)
        logger.error("ERREUR: Summaries Claude Code manquants!")
        logger.error(f"Fichier attendu: {summaries_file}")
        logger.error("")
        logger.error(
            "Claude Code doit generer les summaries AVANT d'executer ce script."
        )
        logger.error("=" * 60)
        sys.exit(1)

    with open(summaries_file, encoding="utf-8") as f:
        summaries_data = json.load(f)

    summaries = summaries_data.get("summaries", {})
    if not summaries:
        logger.error("ERREUR: Fichier summaries vide ou format invalide.")
        logger.error('Format attendu: {"summaries": {"table_id": "summary text", ...}}')
        sys.exit(1)

    logger.info(f"Loaded {len(summaries)} Claude Code summaries")

    # Process tables
    children = []
    parents = []
    parent_lookup = {}
    skipped_no_summary = 0
    skipped_invalid = 0

    for table in tables:
        table_id = table.get("id", "")
        headers = table.get("headers", [])

        # Filter invalid tables
        valid_headers = [h for h in headers if h and str(h).strip()]
        if len(valid_headers) < 2:
            skipped_invalid += 1
            continue

        # Check for Claude Code summary
        summary = summaries.get(table_id)
        if not summary:
            skipped_no_summary += 1
            logger.warning(f"No summary for table: {table_id}")
            continue

        # Create parent (raw table)
        parent = ParentDocument(
            id=table_id,
            type="table",
            table_type=table.get("table_type", "other"),
            source=table.get("source"),
            page=table.get("page"),
            headers=headers,
            rows=table.get("rows", []),
            markdown=table_to_markdown(table),
            text=table.get("text", ""),
        )

        # Create child (summary for embedding)
        child = ChildDocument(
            id=f"{table_id}-summary",
            doc_id=table_id,
            type="table_summary",
            text=summary,
            source=table.get("source"),
            page=table.get("page"),
            table_type=table.get("table_type", "other"),
        )

        parents.append(parent.model_dump())
        children.append(child.model_dump())
        parent_lookup[table_id] = len(parents) - 1

    # Build output
    output = {
        "corpus": corpus,
        "strategy": "multi_vector",
        "summary_source": "claude_code",
        "children": children,
        "parents": parents,
        "parent_lookup": parent_lookup,
        "config": {
            "child_type": "table_summary",
            "parent_type": "table_raw",
            "link_key": "doc_id",
        },
    }

    output_file.parent.mkdir(parents=True, exist_ok=True)
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    logger.info(
        f"Saved {len(children)} children + {len(parents)} parents to {output_file}"
    )

    report = {
        "corpus": corpus,
        "total_tables": len(tables),
        "tables_with_summary": len(children),
        "skipped_no_summary": skipped_no_summary,
        "skipped_invalid_headers": skipped_invalid,
        "summary_source": "claude_code",
    }

    return report


# --- CLI ---


def main() -> None:
    """CLI for multi-vector table processing."""
    parser = argparse.ArgumentParser(
        description="Multi-Vector Table Processor - Pocket Arbiter (Claude Code summaries REQUIRED)",
    )
    parser.add_argument(
        "--input",
        "-i",
        type=Path,
        required=True,
        help="Docling extraction directory",
    )
    parser.add_argument(
        "--summaries",
        "-s",
        type=Path,
        required=True,
        help="Claude Code summaries JSON (REQUIRED)",
    )
    parser.add_argument(
        "--output",
        "-o",
        type=Path,
        required=True,
        help="Output multi-vector JSON",
    )
    parser.add_argument(
        "--corpus",
        "-c",
        type=str,
        choices=["fr", "intl"],
        default="fr",
        help="Corpus name (default: fr)",
    )

    args = parser.parse_args()

    report = process_tables_multivector(
        input_path=args.input,
        summaries_file=args.summaries,
        output_file=args.output,
        corpus=args.corpus,
    )

    logger.info(f"Report: {json.dumps(report, indent=2)}")


if __name__ == "__main__":
    main()
