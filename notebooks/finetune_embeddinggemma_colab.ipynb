{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fine-tuning Embedding Model pour Pocket Arbiter\n",
        "\n",
        "**ISO Reference**: ISO/IEC 42001 A.6.2.2, ISO/IEC 25010 S4.2\n",
        "\n",
        "Ce notebook fine-tune un modele d'embedding multilingue sur le domaine echecs/arbitrage FR.\n",
        "\n",
        "**Instructions**: Clique sur **Execution** â†’ **Tout executer** (c'est tout!)\n",
        "\n",
        "**ZERO configuration requise** - tout est automatique."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Installation des dependances (AUCUN LOGIN REQUIS)\n",
        "!pip install -q sentence-transformers datasets accelerate\n",
        "print(\"Installation terminee!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Verification GPU\n",
        "import torch\n",
        "print(f\"GPU disponible: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "else:\n",
        "    print(\"ATTENTION: Pas de GPU! Va dans Runtime > Change runtime type > GPU\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Telechargement automatique des donnees depuis GitHub\n",
        "!wget -q https://raw.githubusercontent.com/pierrealexandreguillemin-a11y/pocket_arbiter/main/data/training/triplets_training.jsonl\n",
        "print(\"Donnees telechargees!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Chargement des triplets\n",
        "import json\n",
        "\n",
        "triplets = []\n",
        "with open(\"triplets_training.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        if line.strip():\n",
        "            triplets.append(json.loads(line))\n",
        "\n",
        "print(f\"Triplets charges: {len(triplets)}\")\n",
        "print(f\"Exemple: {triplets[0]['anchor'][:50]}...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Configuration\n",
        "# Modele multilingue 768 dimensions - AUCUNE AUTH REQUISE\n",
        "MODEL_ID = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
        "OUTPUT_DIR = \"embedding-chess-fr\"\n",
        "EPOCHS = 3\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 2e-5\n",
        "WARMUP_RATIO = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Chargement du modele (telechargement automatique, pas de login)\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "print(f\"Chargement de {MODEL_ID}...\")\n",
        "model = SentenceTransformer(MODEL_ID)\n",
        "print(f\"Dimension: {model.get_sentence_embedding_dimension()}\")\n",
        "print(\"Modele charge avec succes!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Preparation du dataset\n",
        "from datasets import Dataset\n",
        "\n",
        "dataset = Dataset.from_list(triplets)\n",
        "print(f\"Dataset: {len(dataset)} examples\")\n",
        "print(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Configuration du training\n",
        "from sentence_transformers import (\n",
        "    SentenceTransformerTrainer,\n",
        "    SentenceTransformerTrainingArguments,\n",
        ")\n",
        "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
        "\n",
        "# Loss function\n",
        "loss = MultipleNegativesRankingLoss(model)\n",
        "\n",
        "# Arguments\n",
        "args = SentenceTransformerTrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    warmup_ratio=WARMUP_RATIO,\n",
        "    fp16=True,  # Mixed precision pour GPU\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"epoch\",\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "print(\"Training configure!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Entrainement\n",
        "trainer = SentenceTransformerTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=dataset,\n",
        "    loss=loss,\n",
        ")\n",
        "\n",
        "print(\"Debut de l'entrainement...\")\n",
        "trainer.train()\n",
        "print(\"Entrainement termine!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Sauvegarde du modele\n",
        "model.save(OUTPUT_DIR)\n",
        "print(f\"Modele sauvegarde dans {OUTPUT_DIR}/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test du modele\n",
        "test_queries = [\n",
        "    \"Quelle est la regle du toucher-jouer ?\",\n",
        "    \"Comment fonctionne le roque ?\",\n",
        "    \"Que faire en cas de partie nulle ?\",\n",
        "]\n",
        "\n",
        "print(\"Test du modele fine-tune:\")\n",
        "for q in test_queries:\n",
        "    emb = model.encode(q)\n",
        "    print(f\"  {q[:40]}... -> dim={emb.shape[0]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Telechargement du modele\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Creer une archive\n",
        "shutil.make_archive(OUTPUT_DIR, 'zip', OUTPUT_DIR)\n",
        "print(f\"Archive creee: {OUTPUT_DIR}.zip\")\n",
        "\n",
        "# Telecharger\n",
        "files.download(f\"{OUTPUT_DIR}.zip\")\n",
        "print(\"Telechargement lance! Le fichier va se telecharger automatiquement.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prochaines etapes\n",
        "\n",
        "1. Le fichier `embedding-chess-fr.zip` va se telecharger automatiquement\n",
        "2. Extraire dans `models/`\n",
        "3. Executer `python -m scripts.training.evaluate_finetuned`\n",
        "4. Si recall >= 80%, regenerer les embeddings du corpus"
      ]
    }
  ]
}
