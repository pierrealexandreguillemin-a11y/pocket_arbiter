{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": "# Installation\n!pip install -q \"sentence-transformers[train]\" datasets accelerate huggingface_hub\n!pip install -q git+https://github.com/huggingface/transformers@v4.56.0-Embedding-Gemma-preview\n\n# Login HuggingFace (Kaggle secrets)\nfrom kaggle_secrets import UserSecretsClient\nfrom huggingface_hub import login\n\nsecrets = UserSecretsClient()\nhf_token = secrets.get_secret(\"HF_TOKEN\")\nlogin(token=hf_token)\nprint(\"HuggingFace login OK\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Télécharger les données d'entraînement\n!wget -q https://raw.githubusercontent.com/pierrealexandreguillemin-a11y/pocket_arbiter/main/data/training/triplets_training.jsonl\n\nimport json\ntriplets = [json.loads(l) for l in open(\"triplets_training.jsonl\") if l.strip()]\nprint(f\"Triplets chargés: {len(triplets)}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import torch\nimport gc\nfrom sentence_transformers import SentenceTransformer, SentenceTransformerTrainer, SentenceTransformerTrainingArguments\nfrom sentence_transformers.losses import MultipleNegativesRankingLoss\nfrom datasets import Dataset\n\n# Nettoyer la mémoire\ngc.collect()\ntorch.cuda.empty_cache()\n\n# Info GPU\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Device: {device}\")\nif device == \"cuda\":\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    vram = torch.cuda.get_device_properties(0).total_memory / 1e9\n    print(f\"VRAM: {vram:.1f} GB\")\n\n# Charger EmbeddingGemma\nmodel = SentenceTransformer(\"google/embeddinggemma-300M\", device=device)\nprint(f\"Model loaded: {model.get_sentence_embedding_dimension()} dims\")\n\n# Gradient checkpointing\nmodel[0].auto_model.gradient_checkpointing_enable()\nprint(\"Gradient checkpointing enabled\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Configuration optimisée pour Kaggle GPU (P100/T4)\n# Kaggle a plus de RAM système donc plus de marge\n\ntrainer = SentenceTransformerTrainer(\n    model=model,\n    args=SentenceTransformerTrainingArguments(\n        output_dir=\"embeddinggemma-chess-arbiter-fr\",\n        num_train_epochs=3,\n        per_device_train_batch_size=2,            # Kaggle peut gérer 2\n        gradient_accumulation_steps=8,            # Effective batch = 16\n        learning_rate=2e-5,\n        warmup_ratio=0.1,\n        fp16=False,                               # EmbeddingGemma ne supporte pas fp16\n        bf16=False,\n        logging_steps=50,\n        save_strategy=\"epoch\",\n        report_to=\"none\",\n        dataloader_drop_last=True,\n        optim=\"adamw_torch_fused\",\n        dataloader_num_workers=2,                 # Kaggle a plus de CPU\n    ),\n    train_dataset=Dataset.from_list(triplets),\n    loss=MultipleNegativesRankingLoss(model)\n)\n\nprint(\"Démarrage training...\")\nprint(f\"Steps par epoch: {len(triplets) // 2 // 8}\")\nprint(f\"Total steps: {len(triplets) // 2 // 8 * 3}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# TRAINING\ntrainer.train()\nmodel.save(\"embeddinggemma-chess-arbiter-fr\")\nprint(\"Training terminé!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Évaluation rapide (ISO 42001)\nfrom sentence_transformers import SentenceTransformer\nfrom sentence_transformers.util import cos_sim\nimport random\n\nfinetuned = SentenceTransformer(\"embeddinggemma-chess-arbiter-fr\")\ntest_samples = random.sample(triplets, min(10, len(triplets)))\n\nprint(\"=\" * 60)\nprint(\"ÉVALUATION QUALITÉ (ISO 42001 - Recall)\")\nprint(\"=\" * 60)\n\ncorrect = 0\nfor i, t in enumerate(test_samples):\n    q_emb = finetuned.encode(t[\"anchor\"])\n    pos_emb = finetuned.encode(t[\"positive\"])\n    neg_emb = finetuned.encode(t[\"negative\"])\n    \n    sim_pos = cos_sim(q_emb, pos_emb).item()\n    sim_neg = cos_sim(q_emb, neg_emb).item()\n    \n    is_correct = sim_pos > sim_neg\n    correct += int(is_correct)\n    \n    status = \"OK\" if is_correct else \"FAIL\"\n    print(f\"[{i+1}] {status} | pos={sim_pos:.3f} neg={sim_neg:.3f}\")\n\naccuracy = correct / len(test_samples) * 100\nprint(\"=\" * 60)\nprint(f\"RÉSULTAT: {correct}/{len(test_samples)} = {accuracy:.0f}%\")\nprint(f\"Cible: >=80% → {'PASS' if accuracy >= 80 else 'FAIL'}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Télécharger le modèle fine-tuné\nimport shutil\nshutil.make_archive(\"embeddinggemma-chess-arbiter-fr\", \"zip\", \"embeddinggemma-chess-arbiter-fr\")\n\n# Sur Kaggle: le fichier sera dans /kaggle/working/\nprint(\"Modèle exporté: embeddinggemma-chess-arbiter-fr.zip\")\nprint(\"Télécharge depuis l'onglet 'Output' à droite →\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
